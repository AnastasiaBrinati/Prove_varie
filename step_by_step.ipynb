{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Come affrontare la sfida? non impazzire.\n",
    "questo è iul recap di MOBD."
   ],
   "id": "a2e2a3d27c9aefd9",
   "outputs": null,
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1) Qual è l'obiettivo?\n",
    "2) Problema -> Soluzione -> Risultati\n",
    "3) Documenta ogni passo con chiarezza"
   ],
   "id": "4e7e5fd369050629"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Import librerie\n",
    "\n",
    "Importiamo le librerie principali che useremo per:\n",
    "- analisi dei dati (`pandas`, `numpy`)\n",
    "- visualizzazioni (`matplotlib`, `seaborn`)\n",
    "- modellazione (`scikit-learn`, eventualmente `xgboost`)"
   ],
   "id": "fa1badaaafbe64a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Caricamento dati\n",
    "\n",
    "Carichiamo i dataset principali (es. `train.csv`, `test.csv`) ed esploriamo rapidamente:\n",
    "- le dimensioni (`shape`)\n",
    "- le prime righe (`head()`)\n",
    "- i tipi di dato (`dtypes`)"
   ],
   "id": "4a02210ddf6dfe0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Train-test split\n",
    "- x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=percentage, random_state=seed)\n",
    "\n",
    "- extra tip: **stratify**=y to mantain the same mean as y for y_tr and y_ts\n",
    "- da adesso in poi fai sempre fit_transform sul training set e transform sul test set!!!!!!!!!"
   ],
   "id": "8de7e3db633cc51"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Gestione valori nulli/mancanti\n",
    "- come gestirli?\n",
    "    - riempire ? con 0, avg, knn? imputer w a strategy?\n",
    "    - cancellare le righe ?"
   ],
   "id": "5f99dcf4125634e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Encoding\n",
    "- di che tipo sono le features?\n",
    "- categorical? maybe consider one hot encoding, or binary\n",
    "-"
   ],
   "id": "5117b810bf27089"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Scaling\n",
    "- è necessario?\n",
    "- vedere anche se la maggior parte delle features ha già uno stesso range\n",
    "- scegliere strumento con cui fare lo scaling"
   ],
   "id": "28332629200c3141"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Feature Importance E feature engineering\n",
    "- valutare quali features sono più e meno utili, di solito si fa con random forest classifiers, ma ci sono molte alternative\n",
    "- insieme con passi alternati potrebbe essere necessario valutare feature alternative generate da un processo di ingegnerizzazione dei dati (inventare nuovi attributi)"
   ],
   "id": "c4e259d8afbcb91d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Balancing: classification scenario\n",
    "- sempre bilanciare i campioni di tutte le classi possibili presenti nel training set\n",
    "- in che modo? oversampling o undersampling?\n",
    "- esistono diverse possibli startegie: fare oversampling, seguito da **anomaly detection** e poi undersampling (introduciamo un pò di rumore ma lo 'togliamo' almeno parzialmente subito dopo)"
   ],
   "id": "c6a13337a5a03eb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Anomaly Detection\n",
    "- valutare se necessario lo scarto di data points che risultano fuori dal seminato rispetto al resto (outliers)"
   ],
   "id": "320de7e79212fb58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. Training\n",
    "- ricordiamo sempre chiaramente quale sia il task principale: classificazione, regressione o altro?\n",
    "- seguono esempi di possibili e molto comuni scelte:\n",
    "    - classificazione:\n",
    "        - LogisticRegression\n",
    "        - DecisionTreeClassifier\n",
    "        - RandomForestClassifier\n",
    "        - XGBClassifier\n",
    "    - regressione:\n",
    "        - LinearRegression\n",
    "        - DecisionTreeRegressor\n",
    "        - RandomForestRegressor\n",
    "        - XGBRegressor"
   ],
   "id": "63aaded9e2485553"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 11. Validating\n",
    "- Cross-validation:\n",
    "    - k-fold: partizionare il training set in k fold, k-1 per training e 1 per validare; ripetere il processo più volte per avere diverse divisioni con cui fare addestramenti e validazione.\n",
    "        - from sklearn.model_selection import cross_validate\n",
    "          cv_results = cross_validate(RandomForestClassifier(), X, y, cv=5,scoring=['accuracy', 'f1'], return_train_score=True)\n",
    "- Hyperparameter Tuning:\n",
    "    - GridSearchCV:  preciso, ma lento.\n",
    "    - RandomizedSearchCV\n",
    "    - sempre check manuali\n",
    "- Valutazione: metriche, loss function e visualizzazione, confronto fra modelli e conclusioni"
   ],
   "id": "7e13d461c84e19b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 12. Testing\n",
    "-"
   ],
   "id": "d1b8ac72c96533a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d7a920058cab899e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
